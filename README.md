
## MANIPULANDO O HDFS 

O objetivo deste resposit√≥rio √© desenvolver um exerc√≠cio do treinamento da empresa @Semantix. Esse exerc√≠cio tem como base a manipula√ß√£o do HDFS (Hadoop Distributed File System) distribuindo por etapas. Vale ressaltar que desafio foi desenvolvido em docker! 

üì¢  ETAPA 1: BAIXAR OS DADOS DO EXERC√çCIO 

  > Quest√£o: Baixar os dados dos exerc√≠cios do treinamento

Para baixar os dados do exerc√≠cio foi necess√°rio realizar um clone do github dentro do caminho ```gabriel@hdgabriel:~/docker-bigdata/input$```

[1]

üì¢  ETAPA 2: BAIXAR OS DADOS DO EXERC√çCIO 

  > Quest√£o: Acessar o container do namenode

Ap√≥s baixar a base de dados foi necess√°rio acessar o namenode e listar o seu conte√∫do!

[2]

üì¢  ETAPA 3: BAIXAR OS DADOS DO EXERC√çCIO 

  > Quest√£o: Criar a estrutura de pastas: $ ```user/aluno/seunome/data/recover``` ```user/aluno/seunome/data/delete```

[3]
[4]


üì¢  ETAPA 4: MOVENDO A PASTA E O ARQUIVO

  > Quest√£o: Enviar a pasta ```/input/exercises-data/escola``` e o arquivo ```/input/exercises-data/entrada1.txt``` para ```data```

Para realizar esse processo foi necess√°rio aplicar o seguinte comando para mover a pasta e depois o arquivo:

```root@namenode:/# hdfs dfs -put /input/exercises-data/escola /user/aluno/gabriel/data```
[5]
Agora podemos conferir o resultado do processo de enviar a pasta:
[6]

```root@namenode:/# hdfs dfs -mv /user/aluno/gabriel/data/entrada1.txt /user/aluno/gabriel/recover```
Depois de mover o arquivo, podemos conferir pelo o comando ```hdfs dfs -ls /user/aluno/gabriel/data```
[7]


üì¢  ETAPA 5: MOVENDO O ARQUIVO PARA RECOVER

  > Quest√£o: Mover o arquivo ‚Äúentrada1.txt‚Äù para recover
 
 Para realizar esse processo vamos aplicar o seguinte comando ```root@namenode:/hdfs dfs -mv /user/aluno/gabriel/data/entrada1.txt /user/aluno/gabriel/recover``` e pela figura abaixo √© poss√≠vel observar que dentro da pasta recover se encontra o arquivo ```entrada1.txt```! E dentro da pasta ```data``` agora se encontra vazia!
 [9]
 
 
üì¢  ETAPA 6: DELETANDO RECOVER

  > Quest√£o: Deletar a pasta recover

 Para realizar a etapa 6 foi necessario aplicar o seguinte comando ```root@namenode:/# hdfs dfs -rm -r /user/aluno/gabriel/recover```, e como √© poss√≠vel observar na imagem abaixo, a pasta recover foi direcionado para a lixeira utilizando o ```TrashPolicyDefault```!
 
 [11]
 
 Na figura acima √© poss√≠vel tamb√©m observar que deletando a pasta com o comando ```-skipTrash```, que tem como objetivo deletar a pasta sem passar pela "lixeira tempor√°ria"
  
üì¢  ETAPA 7: PROCURANDO O ARQUIVO NO HDFS

  > Quest√£o: Procurar o arquivo ‚Äúalunos.csv‚Äù dentro do /user
 
 Agora vamos procurar o arquivo ```alunos.csv```  dentro do HDFS e o terminal vai retornar o caminho que se encontra esse arquivo!
  [12]
  
    
üì¢  ETAPA 8: DETALHANDO O ARQUIVO

  > Quest√£o: Mostrar o √∫ltimo 1KB do arquivo ‚Äúalunos.csv‚Äù
  
Para realizar a etapa 8 foi necess√°rio aplicar o comando ```root@namenode:/# hdfs dfs -tail /user/aluno/gabriel/data/escola/alunos.csv``` e o sistema ir√° retornar os registro que equivalem a 1KB do arquivo todo.
[13]

üì¢  ETAPA 9: DETALHANDO OS 5 PRIMEIROS REGISTROS

  > Quest√£o: Mostrar as 5 primeiras linhas do arquivo ‚Äúalunos.csv‚Äù
 
 A etapa 9 pede que detalhamos os 5 primeiros registros do arquivos selecionado, para isso vamos aplicar o comando ```root@namenode:/# hdfs dfs -cat /user/aluno/gabriel/data/escola/alunos.csv | head -n 5```
 [14]
 
 
 
üì¢  ETAPA 10: VERIFICA√á√ÉO DA SOMA DAS INFORMA√á√ïES

  > Quest√£o: Verifica√ß√£o de soma das informa√ß√µes do arquivo ‚Äúalunos.csv‚Äù

O objetivo principal agora √© aplicar um comando que retorne se o arquivo tem consistencia para retornos com put e get. 
[15]

 
üì¢  ETAPA 11: CRIA√á√ÉO E REPLICA√á√ÉO DO ARQUIVO TESTE

  > Quest√£o A: Criar um arquivo em branco com o nome de ‚Äútest‚Äù no data
  > Quest√£o B: Alterar o fator de replica√ß√£o do arquivo ‚Äútest‚Äù para 2
 
 Agora vamos trabalhar com a etapa 11 que pede a cria√ß√£o de um arquivo ```test``` e replicar esse mesmo arquivo para 2  datanode. 
 
 Para realizar a quest√£o A vamos aplicar o comando ```root@namenode:/# hdfs dfs -touchz /user/aluno/gabriel/data/teste``` e para vamos consultar com o comando ```root@namenode:/# hdfs dfs -ls /user/aluno/gabriel/data/```
[16]

 A quest√£o B pede que replicamos o arquivo teste em 2 datanodes, e para isso vamos aplicar o comando ```root@namenode:/# hdfs dfs -setrep 2 /user/aluno/gabriel/data/teste```! Conforme √© poss√≠vel observar na figura 17, a segunda coluna mostra a quantidade de replica√ß√£o! Entretanto, concluimos com sucessa essa etapa.
 [17]
 
 
 üì¢  ETAPA 12: INFORMA√á√ïES DO DISCO

  > Quest√£o: Exibir o espa√ßo livre do data e o uso do disco

Agora vamos realizar algumas consultas do arquivo alunos.csv e do disco. O comando ```stat``` permite trazer alguns informa√ß√µes do arquivo, como √© demostrado na figura abaixo. 

Para realizar a consulta do disco aplicamos o comando ```root@namenode:/# hdfs dfs -du -h /user/aluno/gabriel/data```, onde √© poss√≠vel observar que a pasta escola tem 29.2M e o arquivo teste com o tamanho 0. 
[18]
